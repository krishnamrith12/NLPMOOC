{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Models in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialising the parameter values. Fill in the values before running the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A is the transition probability matrix\n",
    "# pi - initial state probability\n",
    "# O - emission probability\n",
    "\n",
    "A = np.array([[?, 0.1, 0.1],  # Row for H1\n",
    "              [?, ?, 0.1],  # Row for H2\n",
    "              [0.5, ?, 0.0]]) # Row for K2\n",
    "pi = np.array([0.4, 0.35, 0.25])\n",
    "O = np.array([[0.6, 0.2, 0.1,0.1], # Row for H1\n",
    "              [?,?,?,?], # Row for H2\n",
    "              [0.35, 0.2, 0.35,0.1]]) # Row for K2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hidden states are H1, H5, K2\n",
    "- Observations are A1, A2, A3, A4. Here Ax stands for ATM x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states = H1, H5, K2 = 0, 1, 2\n",
    "obs = A1,A2,A3,A4 = 0,1,2,3\n",
    "observations = [A1,A1,A3,A1,A2,A3,A3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exhaustive method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def exhaustive(params, observations):\n",
    "    pi, A, O = params\n",
    "    M = len(observations)\n",
    "    S = pi.shape[0]\n",
    "    \n",
    "    # track the running best sequence and its score\n",
    "    best = (None, float('-inf'))\n",
    "    # loop over the cartesian product of |states|^M\n",
    "    for ss in product(range(S), repeat=M):\n",
    "        # score the state sequence\n",
    "        score = pi[ss[0]] * O[ss[0],observations[0]]\n",
    "        for i in range(1, M):\n",
    "            score *= A[ss[i-1], ss[i]] * O[ss[i], observations[i]]\n",
    "        # update the running best\n",
    "        if score > best[1]:\n",
    "            best = (ss, score)  \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 0, 0, 0, 0, 1, 1), 1.4155776000000005e-05)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exhaustive((pi, A, O), [A1,A1,A3,A1,A2,A3,A3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay, it got the same results as before. Note that the exhaustive method is practical on anything beyond toy data due to the nasty cartesian product. But it is worth doing to verify the Viterbi code above is getting the right results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def viterbi(params, observations):\n",
    "    pi, A, O = params\n",
    "    M = len(observations)\n",
    "    S = pi.shape[0]\n",
    "    \n",
    "    alpha = np.zeros((M, S))\n",
    "    alpha[:,:] = float('-inf')\n",
    "    backpointers = np.zeros((M, S), 'int')\n",
    "    \n",
    "    # base case\n",
    "    alpha[0, :] = pi * O[:,observations[0]]\n",
    "    \n",
    "    # recursive case\n",
    "    for t in range(1, M):\n",
    "        for s2 in range(S):\n",
    "            for s1 in range(S):\n",
    "                score = alpha[t-1, s1] * A[s1, s2] * O[s2, observations[t]]\n",
    "                if score > alpha[t, s2]:\n",
    "                    alpha[t, s2] = score\n",
    "                    backpointers[t, s2] = s1\n",
    "    \n",
    "    # now follow backpointers to resolve the state sequence\n",
    "    ss = []\n",
    "    ss.append(np.argmax(alpha[M-1,:]))\n",
    "    for i in range(M-1, 0, -1):\n",
    "        ss.append(backpointers[i, ss[-1]])\n",
    "        \n",
    "    return list(reversed(ss)), np.max(alpha[M-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 3.3294834175444772e-35)\n"
     ]
    }
   ],
   "source": [
    "res = viterbi((pi, A, O), [A1, A1, A3, A1, A2, A3, A3, A4, A4, A4, A4, A4, A4, A4, A1, A1, A3, A3, A4, A3, A4, A3, A4, A2, A2, A2, A4, A4, A3, A1, A2, A1, A1, A2, A3, A2, A2, A2, A4, A4, A4, A4, A3, A4, A3, A3, A2, A3])\n",
    "print res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Reference\n",
    "- [COMP90042 Web Search and Text Analysis - Trevor Cohn, Univ. of Melbourne](http://people.eng.unimelb.edu.au/tcohn/comp90042.html)\n",
    "- [NLP Course, Autumn 2016 Lecture Notes, IIT Kharagpur](https://github.com/krishnamrith12/NotebooksNLP)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
